{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travelogues MLP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub\n",
    "# https://www.tensorflow.org/tutorials/keras/text_classification_with_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legacy ground truth\n",
    "# True uses only the ground truth used for the creation of the paper, False also inludes travelogues added later\n",
    "legacy = True\n",
    "\n",
    "# century\n",
    "# this defines the century to be used, see travelogues-corpus for more info\n",
    "# valid options: see travelogues-corpus\n",
    "century = '16th_century'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results file\n",
    "result_output = 'results/results_%s_mlp.csv' % century\n",
    "\n",
    "# mlp model name - will be used for saving\n",
    "mlp_model_name = 'models/travelogues_%s_mlp.h5' % century"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load the training data\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "training_categories = []\n",
    "books = ''\n",
    "if legacy is True:\n",
    "    # data directory\n",
    "    books = 'groundtruth/%s/' % century\n",
    "    training_categories = ['travelogues-legacy', 'non-travelogues']\n",
    "else:\n",
    "    # data directory\n",
    "    books = '../travelogues-corpus/%s/books/' % century\n",
    "    training_categories = ['travelogues', 'non-travelogues']\n",
    "\n",
    "travel_gt_path = books\n",
    "    \n",
    "for category in training_categories:\n",
    "    train_path = os.path.join(travel_gt_path, category)\n",
    "    for fname in sorted(os.listdir(train_path)):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(train_path, fname)) as f:\n",
    "                train_texts.append(f.read())\n",
    "            train_labels.append(0 if category == 'non-travelogues' else 1)\n",
    "\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(train_texts, train_labels) \n",
    "\n",
    "# Shuffle the training data and labels.\n",
    "random.seed(seed)\n",
    "random.shuffle(X_train_base)\n",
    "random.seed(seed)\n",
    "random.shuffle(y_train_base)\n",
    "\n",
    "train_labels = np.array(y_train_base)\n",
    "test_labels = np.array(y_test_base)\n",
    "\n",
    "train_texts = X_train_base\n",
    "test_texts = X_test_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_num_words_per_sample(sample_texts):\n",
    "    # median number of words per sample given corpus.\n",
    "    num_words = [len(s.split()) for s in sample_texts]\n",
    "    \n",
    "    return np.median(num_words)\n",
    "\n",
    "def plot_sample_length_distribution(sample_texts):\n",
    "    # plot sample length distribution\n",
    "    \n",
    "    plt.hist([len(s) for s in sample_texts], 50)\n",
    "    plt.xlabel('Length of a sample')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.title('Sample length distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23483.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_words_per_sample(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample_length_distribution(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/dev/venv/travelogues-v/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/home/jan/dev/venv/travelogues-v/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Vectorization parameters\n",
    "ngram_range = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "top_features = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "token_mode = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "min_doc_frequency = 2\n",
    "\n",
    "# Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "kwargs = {\n",
    "        'ngram_range': ngram_range,\n",
    "        'dtype': 'int32',\n",
    "        'strip_accents': 'unicode',\n",
    "        'decode_error': 'replace',\n",
    "        'analyzer': token_mode\n",
    "}\n",
    "vectorizer = HashingVectorizer(**kwargs)\n",
    "\n",
    "# Learn vocabulary from training texts and vectorize training texts.\n",
    "x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Vectorize validation texts.\n",
    "x_val = vectorizer.transform(test_texts)\n",
    "\n",
    "# Select top 'k' of the vectorized features.\n",
    "selector = SelectKBest(f_classif, k=min(top_features, x_train.shape[1]))\n",
    "selector.fit(x_train, train_labels)\n",
    "x_train = selector.transform(x_train).astype('float32')\n",
    "x_val = selector.transform(x_val).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "\n",
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    if num_classes == 2:\n",
    "        activation = 'sigmoid'\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "        units = num_classes\n",
    "    return units, activation\n",
    "\n",
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell needs to be re-run when a saved model is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train_ngram_model(learning_rate=1e-3,\n",
    "                      epochs=1000,\n",
    "                      batch_size=128,\n",
    "                      layers=2,\n",
    "                      units=64,\n",
    "                      dropout_rate=0.2):\n",
    "\n",
    "    # Verify that validation labels are in the same range as training labels.\n",
    "    num_classes = 2\n",
    "    val_labels = y_test_base\n",
    "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
    "    if len(unexpected_labels):\n",
    "        raise ValueError('Unexpected label values found in the validation set:'\n",
    "                         ' {unexpected_labels}. Please make sure that the '\n",
    "                         'labels in the validation set are in the same range '\n",
    "                         'as training labels.'.format(\n",
    "                             unexpected_labels=unexpected_labels))\n",
    "        \n",
    "    model = mlp_model(layers=layers,\n",
    "                                  units=units,\n",
    "                                  dropout_rate=dropout_rate,\n",
    "                                  input_shape=x_train.shape[1:],\n",
    "                                  num_classes=num_classes)\n",
    "\n",
    "    # Compile model with learning parameters.\n",
    "    if num_classes == 2:\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc', f1_score, precision, recall])\n",
    "\n",
    "    # Create callback for early stopping on validation loss. If the loss does\n",
    "    # not decrease in 50 consecutive tries, stop training.\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "            x_train,\n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, val_labels),\n",
    "            verbose=2,  # Logs once per epoch.\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # Print results.\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "    \n",
    "    # plot history\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Save model.\n",
    "    model.save(mlp_model_name)\n",
    "    return history['val_acc'][-1], history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jan/dev/venv/travelogues-v/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/jan/dev/venv/travelogues-v/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 100 samples, validate on 34 samples\n",
      "Epoch 1/1000\n",
      "100/100 - 1s - loss: 0.6923 - acc: 0.6200 - f1_score: 0.5476 - precision: 0.7188 - recall: 0.4423 - val_loss: 0.6889 - val_acc: 0.6176 - val_f1_score: 0.6977 - val_precision: 0.5357 - val_recall: 1.0000\n",
      "Epoch 2/1000\n",
      "100/100 - 0s - loss: 0.6862 - acc: 0.7100 - f1_score: 0.7820 - precision: 0.6420 - recall: 1.0000 - val_loss: 0.6859 - val_acc: 0.5294 - val_f1_score: 0.6522 - val_precision: 0.4839 - val_recall: 1.0000\n",
      "Epoch 3/1000\n",
      "100/100 - 0s - loss: 0.6810 - acc: 0.7500 - f1_score: 0.8062 - precision: 0.6753 - recall: 1.0000 - val_loss: 0.6828 - val_acc: 0.5588 - val_f1_score: 0.6667 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 4/1000\n",
      "100/100 - 0s - loss: 0.6761 - acc: 0.7300 - f1_score: 0.7939 - precision: 0.6582 - recall: 1.0000 - val_loss: 0.6791 - val_acc: 0.5588 - val_f1_score: 0.6667 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 5/1000\n",
      "100/100 - 0s - loss: 0.6688 - acc: 0.8000 - f1_score: 0.8387 - precision: 0.7222 - recall: 1.0000 - val_loss: 0.6751 - val_acc: 0.5588 - val_f1_score: 0.6667 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 6/1000\n",
      "100/100 - 0s - loss: 0.6616 - acc: 0.8400 - f1_score: 0.8667 - precision: 0.7647 - recall: 1.0000 - val_loss: 0.6708 - val_acc: 0.5588 - val_f1_score: 0.6667 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 7/1000\n",
      "100/100 - 0s - loss: 0.6566 - acc: 0.8400 - f1_score: 0.8667 - precision: 0.7647 - recall: 1.0000 - val_loss: 0.6663 - val_acc: 0.6176 - val_f1_score: 0.6977 - val_precision: 0.5357 - val_recall: 1.0000\n",
      "Epoch 8/1000\n",
      "100/100 - 0s - loss: 0.6490 - acc: 0.8400 - f1_score: 0.8667 - precision: 0.7647 - recall: 1.0000 - val_loss: 0.6616 - val_acc: 0.6471 - val_f1_score: 0.7143 - val_precision: 0.5556 - val_recall: 1.0000\n",
      "Epoch 9/1000\n",
      "100/100 - 0s - loss: 0.6418 - acc: 0.8800 - f1_score: 0.8966 - precision: 0.8125 - recall: 1.0000 - val_loss: 0.6569 - val_acc: 0.7353 - val_f1_score: 0.7692 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 10/1000\n",
      "100/100 - 0s - loss: 0.6351 - acc: 0.8800 - f1_score: 0.8966 - precision: 0.8125 - recall: 1.0000 - val_loss: 0.6522 - val_acc: 0.7353 - val_f1_score: 0.7692 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 11/1000\n",
      "100/100 - 0s - loss: 0.6285 - acc: 0.8600 - f1_score: 0.8814 - precision: 0.7879 - recall: 1.0000 - val_loss: 0.6474 - val_acc: 0.7353 - val_f1_score: 0.7692 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 12/1000\n",
      "100/100 - 0s - loss: 0.6209 - acc: 0.9000 - f1_score: 0.9123 - precision: 0.8387 - recall: 1.0000 - val_loss: 0.6426 - val_acc: 0.7353 - val_f1_score: 0.7692 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 13/1000\n",
      "100/100 - 0s - loss: 0.6128 - acc: 0.9100 - f1_score: 0.9204 - precision: 0.8525 - recall: 1.0000 - val_loss: 0.6378 - val_acc: 0.7647 - val_f1_score: 0.7895 - val_precision: 0.6522 - val_recall: 1.0000\n",
      "Epoch 14/1000\n",
      "100/100 - 0s - loss: 0.6026 - acc: 0.8900 - f1_score: 0.9043 - precision: 0.8254 - recall: 1.0000 - val_loss: 0.6330 - val_acc: 0.7647 - val_f1_score: 0.7895 - val_precision: 0.6522 - val_recall: 1.0000\n",
      "Epoch 15/1000\n",
      "100/100 - 0s - loss: 0.5999 - acc: 0.9300 - f1_score: 0.9369 - precision: 0.8814 - recall: 1.0000 - val_loss: 0.6281 - val_acc: 0.7647 - val_f1_score: 0.7895 - val_precision: 0.6522 - val_recall: 1.0000\n",
      "Epoch 16/1000\n",
      "100/100 - 0s - loss: 0.5917 - acc: 0.9100 - f1_score: 0.9204 - precision: 0.8525 - recall: 1.0000 - val_loss: 0.6232 - val_acc: 0.7941 - val_f1_score: 0.8108 - val_precision: 0.6818 - val_recall: 1.0000\n",
      "Epoch 17/1000\n",
      "100/100 - 0s - loss: 0.5840 - acc: 0.9200 - f1_score: 0.9286 - precision: 0.8667 - recall: 1.0000 - val_loss: 0.6183 - val_acc: 0.7941 - val_f1_score: 0.8108 - val_precision: 0.6818 - val_recall: 1.0000\n",
      "Epoch 18/1000\n",
      "100/100 - 0s - loss: 0.5757 - acc: 0.9400 - f1_score: 0.9455 - precision: 0.8966 - recall: 1.0000 - val_loss: 0.6133 - val_acc: 0.8235 - val_f1_score: 0.8333 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 19/1000\n",
      "100/100 - 0s - loss: 0.5701 - acc: 0.9200 - f1_score: 0.9286 - precision: 0.8667 - recall: 1.0000 - val_loss: 0.6084 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 20/1000\n",
      "100/100 - 0s - loss: 0.5616 - acc: 0.9300 - f1_score: 0.9369 - precision: 0.8814 - recall: 1.0000 - val_loss: 0.6034 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 21/1000\n",
      "100/100 - 0s - loss: 0.5495 - acc: 0.9300 - f1_score: 0.9369 - precision: 0.8814 - recall: 1.0000 - val_loss: 0.5983 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 22/1000\n",
      "100/100 - 0s - loss: 0.5500 - acc: 0.9300 - f1_score: 0.9358 - precision: 0.8947 - recall: 0.9808 - val_loss: 0.5933 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 23/1000\n",
      "100/100 - 0s - loss: 0.5417 - acc: 0.9200 - f1_score: 0.9259 - precision: 0.8929 - recall: 0.9615 - val_loss: 0.5882 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 24/1000\n",
      "100/100 - 0s - loss: 0.5348 - acc: 0.9500 - f1_score: 0.9541 - precision: 0.9123 - recall: 1.0000 - val_loss: 0.5832 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 25/1000\n",
      "100/100 - 0s - loss: 0.5208 - acc: 0.9500 - f1_score: 0.9533 - precision: 0.9273 - recall: 0.9808 - val_loss: 0.5783 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 26/1000\n",
      "100/100 - 0s - loss: 0.5131 - acc: 0.9300 - f1_score: 0.9346 - precision: 0.9091 - recall: 0.9615 - val_loss: 0.5733 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 27/1000\n",
      "100/100 - 0s - loss: 0.5055 - acc: 0.9400 - f1_score: 0.9444 - precision: 0.9107 - recall: 0.9808 - val_loss: 0.5683 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 28/1000\n",
      "100/100 - 0s - loss: 0.5053 - acc: 0.9300 - f1_score: 0.9358 - precision: 0.8947 - recall: 0.9808 - val_loss: 0.5634 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 29/1000\n",
      "100/100 - 0s - loss: 0.4950 - acc: 0.9300 - f1_score: 0.9358 - precision: 0.8947 - recall: 0.9808 - val_loss: 0.5585 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 30/1000\n",
      "100/100 - 0s - loss: 0.4893 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.5536 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 31/1000\n",
      "100/100 - 0s - loss: 0.4774 - acc: 0.9500 - f1_score: 0.9533 - precision: 0.9273 - recall: 0.9808 - val_loss: 0.5488 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 32/1000\n",
      "100/100 - 0s - loss: 0.4707 - acc: 0.9500 - f1_score: 0.9533 - precision: 0.9273 - recall: 0.9808 - val_loss: 0.5440 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 33/1000\n",
      "100/100 - 0s - loss: 0.4644 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.5391 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 34/1000\n",
      "100/100 - 0s - loss: 0.4559 - acc: 0.9500 - f1_score: 0.9541 - precision: 0.9123 - recall: 1.0000 - val_loss: 0.5341 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 35/1000\n",
      "100/100 - 0s - loss: 0.4487 - acc: 0.9400 - f1_score: 0.9444 - precision: 0.9107 - recall: 0.9808 - val_loss: 0.5293 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "100/100 - 0s - loss: 0.4373 - acc: 0.9500 - f1_score: 0.9533 - precision: 0.9273 - recall: 0.9808 - val_loss: 0.5244 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 37/1000\n",
      "100/100 - 0s - loss: 0.4320 - acc: 0.9300 - f1_score: 0.9346 - precision: 0.9091 - recall: 0.9615 - val_loss: 0.5196 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 38/1000\n",
      "100/100 - 0s - loss: 0.4341 - acc: 0.9400 - f1_score: 0.9434 - precision: 0.9259 - recall: 0.9615 - val_loss: 0.5149 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 39/1000\n",
      "100/100 - 0s - loss: 0.4302 - acc: 0.9500 - f1_score: 0.9541 - precision: 0.9123 - recall: 1.0000 - val_loss: 0.5102 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 40/1000\n",
      "100/100 - 0s - loss: 0.4195 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.5055 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 41/1000\n",
      "100/100 - 0s - loss: 0.4109 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.5009 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 42/1000\n",
      "100/100 - 0s - loss: 0.4096 - acc: 0.9300 - f1_score: 0.9358 - precision: 0.8947 - recall: 0.9808 - val_loss: 0.4962 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 43/1000\n",
      "100/100 - 0s - loss: 0.3936 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4917 - val_acc: 0.8529 - val_f1_score: 0.8571 - val_precision: 0.7500 - val_recall: 1.0000\n",
      "Epoch 44/1000\n",
      "100/100 - 0s - loss: 0.3994 - acc: 0.9400 - f1_score: 0.9434 - precision: 0.9259 - recall: 0.9615 - val_loss: 0.4872 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 45/1000\n",
      "100/100 - 0s - loss: 0.3864 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4827 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 46/1000\n",
      "100/100 - 0s - loss: 0.3775 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4784 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 47/1000\n",
      "100/100 - 0s - loss: 0.3772 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.4741 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 48/1000\n",
      "100/100 - 0s - loss: 0.3771 - acc: 0.9400 - f1_score: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.4698 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 49/1000\n",
      "100/100 - 0s - loss: 0.3636 - acc: 0.9400 - f1_score: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.4657 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 50/1000\n",
      "100/100 - 0s - loss: 0.3548 - acc: 0.9400 - f1_score: 0.9444 - precision: 0.9107 - recall: 0.9808 - val_loss: 0.4616 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 51/1000\n",
      "100/100 - 0s - loss: 0.3489 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4575 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 52/1000\n",
      "100/100 - 0s - loss: 0.3489 - acc: 0.9400 - f1_score: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.4535 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 53/1000\n",
      "100/100 - 0s - loss: 0.3384 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.4496 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 54/1000\n",
      "100/100 - 0s - loss: 0.3346 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4458 - val_acc: 0.8824 - val_f1_score: 0.8824 - val_precision: 0.7895 - val_recall: 1.0000\n",
      "Epoch 55/1000\n",
      "100/100 - 0s - loss: 0.3317 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4422 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 56/1000\n",
      "100/100 - 0s - loss: 0.3178 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.4386 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 57/1000\n",
      "100/100 - 0s - loss: 0.3173 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.4350 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 58/1000\n",
      "100/100 - 0s - loss: 0.3073 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.4314 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 59/1000\n",
      "100/100 - 0s - loss: 0.3111 - acc: 0.9500 - f1_score: 0.9533 - precision: 0.9273 - recall: 0.9808 - val_loss: 0.4278 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 60/1000\n",
      "100/100 - 0s - loss: 0.3049 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.4244 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 61/1000\n",
      "100/100 - 0s - loss: 0.2982 - acc: 0.9400 - f1_score: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.4210 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 62/1000\n",
      "100/100 - 0s - loss: 0.3012 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.4177 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 63/1000\n",
      "100/100 - 0s - loss: 0.2919 - acc: 0.9400 - f1_score: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.4144 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 64/1000\n",
      "100/100 - 0s - loss: 0.2941 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.4112 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 65/1000\n",
      "100/100 - 0s - loss: 0.2769 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.4078 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 66/1000\n",
      "100/100 - 0s - loss: 0.2781 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.4047 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 67/1000\n",
      "100/100 - 0s - loss: 0.2712 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.4015 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 68/1000\n",
      "100/100 - 0s - loss: 0.2754 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3984 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 69/1000\n",
      "100/100 - 0s - loss: 0.2649 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3952 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 70/1000\n",
      "100/100 - 0s - loss: 0.2645 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3922 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 71/1000\n",
      "100/100 - 0s - loss: 0.2524 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3893 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 72/1000\n",
      "100/100 - 0s - loss: 0.2577 - acc: 0.9700 - f1_score: 0.9714 - precision: 0.9623 - recall: 0.9808 - val_loss: 0.3866 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 73/1000\n",
      "100/100 - 0s - loss: 0.2533 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3840 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "100/100 - 0s - loss: 0.2491 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3815 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 75/1000\n",
      "100/100 - 0s - loss: 0.2417 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3792 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 76/1000\n",
      "100/100 - 0s - loss: 0.2457 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3769 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 77/1000\n",
      "100/100 - 0s - loss: 0.2360 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3746 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 78/1000\n",
      "100/100 - 0s - loss: 0.2404 - acc: 0.9600 - f1_score: 0.9608 - precision: 0.9800 - recall: 0.9423 - val_loss: 0.3723 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 79/1000\n",
      "100/100 - 0s - loss: 0.2288 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3702 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 80/1000\n",
      "100/100 - 0s - loss: 0.2295 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3680 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 81/1000\n",
      "100/100 - 0s - loss: 0.2306 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.3659 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 82/1000\n",
      "100/100 - 0s - loss: 0.2213 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3638 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 83/1000\n",
      "100/100 - 0s - loss: 0.2196 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3618 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 84/1000\n",
      "100/100 - 0s - loss: 0.2163 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3599 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 85/1000\n",
      "100/100 - 0s - loss: 0.2212 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3580 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 86/1000\n",
      "100/100 - 0s - loss: 0.2127 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3562 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 87/1000\n",
      "100/100 - 0s - loss: 0.2025 - acc: 0.9500 - f1_score: 0.9524 - precision: 0.9434 - recall: 0.9615 - val_loss: 0.3545 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 88/1000\n",
      "100/100 - 0s - loss: 0.2134 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3528 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 89/1000\n",
      "100/100 - 0s - loss: 0.1973 - acc: 0.9700 - f1_score: 0.9714 - precision: 0.9623 - recall: 0.9808 - val_loss: 0.3512 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 90/1000\n",
      "100/100 - 0s - loss: 0.1927 - acc: 0.9600 - f1_score: 0.9608 - precision: 0.9800 - recall: 0.9423 - val_loss: 0.3496 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 91/1000\n",
      "100/100 - 0s - loss: 0.1960 - acc: 0.9600 - f1_score: 0.9608 - precision: 0.9800 - recall: 0.9423 - val_loss: 0.3481 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 92/1000\n",
      "100/100 - 0s - loss: 0.1872 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3466 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 93/1000\n",
      "100/100 - 0s - loss: 0.1814 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3451 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 94/1000\n",
      "100/100 - 0s - loss: 0.1901 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3435 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 95/1000\n",
      "100/100 - 0s - loss: 0.1927 - acc: 0.9600 - f1_score: 0.9608 - precision: 0.9800 - recall: 0.9423 - val_loss: 0.3419 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 96/1000\n",
      "100/100 - 0s - loss: 0.1852 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3404 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 97/1000\n",
      "100/100 - 0s - loss: 0.1860 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3388 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 98/1000\n",
      "100/100 - 0s - loss: 0.1811 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3373 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 99/1000\n",
      "100/100 - 0s - loss: 0.1672 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3358 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 100/1000\n",
      "100/100 - 0s - loss: 0.1797 - acc: 0.9600 - f1_score: 0.9623 - precision: 0.9444 - recall: 0.9808 - val_loss: 0.3344 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 101/1000\n",
      "100/100 - 0s - loss: 0.1706 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3328 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 102/1000\n",
      "100/100 - 0s - loss: 0.1642 - acc: 0.9700 - f1_score: 0.9714 - precision: 0.9623 - recall: 0.9808 - val_loss: 0.3313 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 103/1000\n",
      "100/100 - 0s - loss: 0.1716 - acc: 0.9700 - f1_score: 0.9714 - precision: 0.9623 - recall: 0.9808 - val_loss: 0.3297 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 104/1000\n",
      "100/100 - 0s - loss: 0.1650 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3282 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 105/1000\n",
      "100/100 - 0s - loss: 0.1693 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3266 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 106/1000\n",
      "100/100 - 0s - loss: 0.1706 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3251 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 107/1000\n",
      "100/100 - 0s - loss: 0.1634 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3236 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 108/1000\n",
      "100/100 - 0s - loss: 0.1606 - acc: 0.9500 - f1_score: 0.9515 - precision: 0.9608 - recall: 0.9423 - val_loss: 0.3223 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 109/1000\n",
      "100/100 - 0s - loss: 0.1530 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3209 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 110/1000\n",
      "100/100 - 0s - loss: 0.1562 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3196 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 111/1000\n",
      "100/100 - 0s - loss: 0.1508 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3184 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "100/100 - 0s - loss: 0.1568 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3172 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 113/1000\n",
      "100/100 - 0s - loss: 0.1490 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3159 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 114/1000\n",
      "100/100 - 0s - loss: 0.1477 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.3146 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 115/1000\n",
      "100/100 - 0s - loss: 0.1547 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3135 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 116/1000\n",
      "100/100 - 0s - loss: 0.1461 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3124 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 117/1000\n",
      "100/100 - 0s - loss: 0.1433 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3113 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 118/1000\n",
      "100/100 - 0s - loss: 0.1418 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3102 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 119/1000\n",
      "100/100 - 0s - loss: 0.1501 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3091 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 120/1000\n",
      "100/100 - 0s - loss: 0.1353 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.3079 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 121/1000\n",
      "100/100 - 0s - loss: 0.1372 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3070 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 122/1000\n",
      "100/100 - 0s - loss: 0.1397 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3061 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 123/1000\n",
      "100/100 - 0s - loss: 0.1424 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.3055 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 124/1000\n",
      "100/100 - 0s - loss: 0.1352 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3049 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 125/1000\n",
      "100/100 - 0s - loss: 0.1337 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3043 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 126/1000\n",
      "100/100 - 0s - loss: 0.1282 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3039 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 127/1000\n",
      "100/100 - 0s - loss: 0.1243 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3033 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 128/1000\n",
      "100/100 - 0s - loss: 0.1256 - acc: 0.9900 - f1_score: 0.9903 - precision: 1.0000 - recall: 0.9808 - val_loss: 0.3027 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 129/1000\n",
      "100/100 - 0s - loss: 0.1317 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3022 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 130/1000\n",
      "100/100 - 0s - loss: 0.1343 - acc: 0.9700 - f1_score: 0.9714 - precision: 0.9623 - recall: 0.9808 - val_loss: 0.3017 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 131/1000\n",
      "100/100 - 0s - loss: 0.1281 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.3012 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 132/1000\n",
      "100/100 - 0s - loss: 0.1298 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.3006 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 133/1000\n",
      "100/100 - 0s - loss: 0.1185 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2999 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 134/1000\n",
      "100/100 - 0s - loss: 0.1148 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2991 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 135/1000\n",
      "100/100 - 0s - loss: 0.1203 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.2983 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 136/1000\n",
      "100/100 - 0s - loss: 0.1183 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2974 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 137/1000\n",
      "100/100 - 0s - loss: 0.1179 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2964 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 138/1000\n",
      "100/100 - 0s - loss: 0.1141 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2953 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 139/1000\n",
      "100/100 - 0s - loss: 0.1267 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.2942 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 140/1000\n",
      "100/100 - 0s - loss: 0.1015 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2931 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 141/1000\n",
      "100/100 - 0s - loss: 0.1096 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2921 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 142/1000\n",
      "100/100 - 0s - loss: 0.1139 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2912 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 143/1000\n",
      "100/100 - 0s - loss: 0.1106 - acc: 0.9600 - f1_score: 0.9615 - precision: 0.9615 - recall: 0.9615 - val_loss: 0.2903 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 144/1000\n",
      "100/100 - 0s - loss: 0.1060 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2894 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 145/1000\n",
      "100/100 - 0s - loss: 0.1163 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2886 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 146/1000\n",
      "100/100 - 0s - loss: 0.1064 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2878 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 147/1000\n",
      "100/100 - 0s - loss: 0.1092 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2870 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 148/1000\n",
      "100/100 - 0s - loss: 0.1052 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2863 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 149/1000\n",
      "100/100 - 0s - loss: 0.1079 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2856 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "100/100 - 0s - loss: 0.1064 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.2850 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 151/1000\n",
      "100/100 - 0s - loss: 0.1119 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2845 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 152/1000\n",
      "100/100 - 0s - loss: 0.0977 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2839 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 153/1000\n",
      "100/100 - 0s - loss: 0.1097 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2830 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 154/1000\n",
      "100/100 - 0s - loss: 0.1037 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2824 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 155/1000\n",
      "100/100 - 0s - loss: 0.0977 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2817 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 156/1000\n",
      "100/100 - 0s - loss: 0.0968 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2810 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 157/1000\n",
      "100/100 - 0s - loss: 0.0993 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.2806 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 158/1000\n",
      "100/100 - 0s - loss: 0.0921 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2800 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 159/1000\n",
      "100/100 - 0s - loss: 0.0890 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2792 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 160/1000\n",
      "100/100 - 0s - loss: 0.0973 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2786 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 161/1000\n",
      "100/100 - 0s - loss: 0.0958 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2780 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 162/1000\n",
      "100/100 - 0s - loss: 0.0875 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2774 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 163/1000\n",
      "100/100 - 0s - loss: 0.0960 - acc: 0.9700 - f1_score: 0.9709 - precision: 0.9804 - recall: 0.9615 - val_loss: 0.2768 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 164/1000\n",
      "100/100 - 0s - loss: 0.0896 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2760 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 165/1000\n",
      "100/100 - 0s - loss: 0.0976 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2751 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 166/1000\n",
      "100/100 - 0s - loss: 0.0817 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2742 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 167/1000\n",
      "100/100 - 0s - loss: 0.0871 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2732 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 168/1000\n",
      "100/100 - 0s - loss: 0.0846 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2724 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 169/1000\n",
      "100/100 - 0s - loss: 0.0818 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2718 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 170/1000\n",
      "100/100 - 0s - loss: 0.0814 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2710 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 171/1000\n",
      "100/100 - 0s - loss: 0.0770 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2702 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 172/1000\n",
      "100/100 - 0s - loss: 0.0834 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2693 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 173/1000\n",
      "100/100 - 0s - loss: 0.0891 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2683 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 174/1000\n",
      "100/100 - 0s - loss: 0.0799 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2672 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 175/1000\n",
      "100/100 - 0s - loss: 0.0795 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2664 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 176/1000\n",
      "100/100 - 0s - loss: 0.0764 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2655 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 177/1000\n",
      "100/100 - 0s - loss: 0.0789 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2647 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 178/1000\n",
      "100/100 - 0s - loss: 0.0810 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2641 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 179/1000\n",
      "100/100 - 0s - loss: 0.0769 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2639 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 180/1000\n",
      "100/100 - 0s - loss: 0.0751 - acc: 0.9900 - f1_score: 0.9903 - precision: 1.0000 - recall: 0.9808 - val_loss: 0.2639 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 181/1000\n",
      "100/100 - 0s - loss: 0.0758 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2637 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 182/1000\n",
      "100/100 - 0s - loss: 0.0727 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2635 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 183/1000\n",
      "100/100 - 0s - loss: 0.0821 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2631 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 184/1000\n",
      "100/100 - 0s - loss: 0.0747 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2627 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 185/1000\n",
      "100/100 - 0s - loss: 0.0787 - acc: 0.9800 - f1_score: 0.9808 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.2624 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 186/1000\n",
      "100/100 - 0s - loss: 0.0767 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2622 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 187/1000\n",
      "100/100 - 0s - loss: 0.0677 - acc: 0.9900 - f1_score: 0.9903 - precision: 1.0000 - recall: 0.9808 - val_loss: 0.2621 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000\n",
      "100/100 - 0s - loss: 0.0686 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2619 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 189/1000\n",
      "100/100 - 0s - loss: 0.0673 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2617 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 190/1000\n",
      "100/100 - 0s - loss: 0.0642 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2614 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 191/1000\n",
      "100/100 - 0s - loss: 0.0704 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2614 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 192/1000\n",
      "100/100 - 0s - loss: 0.0657 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2610 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 193/1000\n",
      "100/100 - 0s - loss: 0.0665 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2608 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 194/1000\n",
      "100/100 - 0s - loss: 0.0715 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2603 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 195/1000\n",
      "100/100 - 0s - loss: 0.0621 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2601 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 196/1000\n",
      "100/100 - 0s - loss: 0.0674 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2598 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 197/1000\n",
      "100/100 - 0s - loss: 0.0680 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2592 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 198/1000\n",
      "100/100 - 0s - loss: 0.0609 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2585 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 199/1000\n",
      "100/100 - 0s - loss: 0.0583 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2577 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 200/1000\n",
      "100/100 - 0s - loss: 0.0739 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2569 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 201/1000\n",
      "100/100 - 0s - loss: 0.0575 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2561 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 202/1000\n",
      "100/100 - 0s - loss: 0.0601 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2555 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 203/1000\n",
      "100/100 - 0s - loss: 0.0603 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2550 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 204/1000\n",
      "100/100 - 0s - loss: 0.0598 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2545 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 205/1000\n",
      "100/100 - 0s - loss: 0.0591 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2538 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 206/1000\n",
      "100/100 - 0s - loss: 0.0572 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2530 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 207/1000\n",
      "100/100 - 0s - loss: 0.0646 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2523 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 208/1000\n",
      "100/100 - 0s - loss: 0.0610 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2514 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 209/1000\n",
      "100/100 - 0s - loss: 0.0577 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2507 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 210/1000\n",
      "100/100 - 0s - loss: 0.0509 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2505 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 211/1000\n",
      "100/100 - 0s - loss: 0.0584 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2506 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 212/1000\n",
      "100/100 - 0s - loss: 0.0563 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2505 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 213/1000\n",
      "100/100 - 0s - loss: 0.0523 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2503 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 214/1000\n",
      "100/100 - 0s - loss: 0.0623 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2502 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 215/1000\n",
      "100/100 - 0s - loss: 0.0574 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2502 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 216/1000\n",
      "100/100 - 0s - loss: 0.0582 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2503 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 217/1000\n",
      "100/100 - 0s - loss: 0.0566 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2503 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 218/1000\n",
      "100/100 - 0s - loss: 0.0531 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2507 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 219/1000\n",
      "100/100 - 0s - loss: 0.0505 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2510 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 220/1000\n",
      "100/100 - 0s - loss: 0.0540 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2513 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 221/1000\n",
      "100/100 - 0s - loss: 0.0529 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2513 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 222/1000\n",
      "100/100 - 0s - loss: 0.0536 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2511 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 223/1000\n",
      "100/100 - 0s - loss: 0.0512 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2510 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 224/1000\n",
      "100/100 - 0s - loss: 0.0475 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2510 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 225/1000\n",
      "100/100 - 0s - loss: 0.0520 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2508 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "100/100 - 0s - loss: 0.0443 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2506 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 227/1000\n",
      "100/100 - 0s - loss: 0.0450 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2503 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 228/1000\n",
      "100/100 - 0s - loss: 0.0557 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2498 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 229/1000\n",
      "100/100 - 0s - loss: 0.0516 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2490 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 230/1000\n",
      "100/100 - 0s - loss: 0.0540 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2479 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 231/1000\n",
      "100/100 - 0s - loss: 0.0457 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2466 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 232/1000\n",
      "100/100 - 0s - loss: 0.0482 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2452 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 233/1000\n",
      "100/100 - 0s - loss: 0.0456 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2441 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 234/1000\n",
      "100/100 - 0s - loss: 0.0497 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2431 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 235/1000\n",
      "100/100 - 0s - loss: 0.0420 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2424 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 236/1000\n",
      "100/100 - 0s - loss: 0.0396 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2417 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 237/1000\n",
      "100/100 - 0s - loss: 0.0470 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2412 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 238/1000\n",
      "100/100 - 0s - loss: 0.0492 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2408 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 239/1000\n",
      "100/100 - 0s - loss: 0.0457 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2404 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 240/1000\n",
      "100/100 - 0s - loss: 0.0466 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2403 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 241/1000\n",
      "100/100 - 0s - loss: 0.0451 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2402 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 242/1000\n",
      "100/100 - 0s - loss: 0.0484 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2403 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 243/1000\n",
      "100/100 - 0s - loss: 0.0435 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2406 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 244/1000\n",
      "100/100 - 0s - loss: 0.0437 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2411 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 245/1000\n",
      "100/100 - 0s - loss: 0.0462 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2416 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 246/1000\n",
      "100/100 - 0s - loss: 0.0431 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2417 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 247/1000\n",
      "100/100 - 0s - loss: 0.0459 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2421 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 248/1000\n",
      "100/100 - 0s - loss: 0.0410 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2423 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 249/1000\n",
      "100/100 - 0s - loss: 0.0416 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2426 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 250/1000\n",
      "100/100 - 0s - loss: 0.0409 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2428 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 251/1000\n",
      "100/100 - 0s - loss: 0.0413 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2428 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 252/1000\n",
      "100/100 - 0s - loss: 0.0462 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2426 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 253/1000\n",
      "100/100 - 0s - loss: 0.0384 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2421 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 254/1000\n",
      "100/100 - 0s - loss: 0.0351 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2416 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 255/1000\n",
      "100/100 - 0s - loss: 0.0411 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2411 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 256/1000\n",
      "100/100 - 0s - loss: 0.0422 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2404 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 257/1000\n",
      "100/100 - 0s - loss: 0.0347 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2399 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 258/1000\n",
      "100/100 - 0s - loss: 0.0421 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2392 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 259/1000\n",
      "100/100 - 0s - loss: 0.0375 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2386 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 260/1000\n",
      "100/100 - 0s - loss: 0.0342 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2381 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 261/1000\n",
      "100/100 - 0s - loss: 0.0349 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2378 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 262/1000\n",
      "100/100 - 0s - loss: 0.0398 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2372 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 263/1000\n",
      "100/100 - 0s - loss: 0.0362 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2365 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/1000\n",
      "100/100 - 0s - loss: 0.0360 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2360 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 265/1000\n",
      "100/100 - 0s - loss: 0.0393 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2357 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 266/1000\n",
      "100/100 - 0s - loss: 0.0340 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2354 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 267/1000\n",
      "100/100 - 0s - loss: 0.0364 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2354 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 268/1000\n",
      "100/100 - 0s - loss: 0.0288 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2354 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 269/1000\n",
      "100/100 - 0s - loss: 0.0360 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2355 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 270/1000\n",
      "100/100 - 0s - loss: 0.0347 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2357 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 271/1000\n",
      "100/100 - 0s - loss: 0.0390 - acc: 0.9900 - f1_score: 0.9905 - precision: 0.9811 - recall: 1.0000 - val_loss: 0.2354 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 272/1000\n",
      "100/100 - 0s - loss: 0.0369 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2349 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 273/1000\n",
      "100/100 - 0s - loss: 0.0360 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2342 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 274/1000\n",
      "100/100 - 0s - loss: 0.0329 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2334 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 275/1000\n",
      "100/100 - 0s - loss: 0.0303 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2328 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 276/1000\n",
      "100/100 - 0s - loss: 0.0329 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2326 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 277/1000\n",
      "100/100 - 0s - loss: 0.0359 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2325 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 278/1000\n",
      "100/100 - 0s - loss: 0.0342 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2323 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 279/1000\n",
      "100/100 - 0s - loss: 0.0280 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2321 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 280/1000\n",
      "100/100 - 0s - loss: 0.0335 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2319 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 281/1000\n",
      "100/100 - 0s - loss: 0.0287 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2319 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 282/1000\n",
      "100/100 - 0s - loss: 0.0282 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2319 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 283/1000\n",
      "100/100 - 0s - loss: 0.0314 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2319 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 284/1000\n",
      "100/100 - 0s - loss: 0.0297 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2318 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 285/1000\n",
      "100/100 - 0s - loss: 0.0292 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2315 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 286/1000\n",
      "100/100 - 0s - loss: 0.0326 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2314 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 287/1000\n",
      "100/100 - 0s - loss: 0.0331 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2310 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 288/1000\n",
      "100/100 - 0s - loss: 0.0306 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 289/1000\n",
      "100/100 - 0s - loss: 0.0297 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 290/1000\n",
      "100/100 - 0s - loss: 0.0286 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2304 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 291/1000\n",
      "100/100 - 0s - loss: 0.0292 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2304 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 292/1000\n",
      "100/100 - 0s - loss: 0.0316 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2305 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 293/1000\n",
      "100/100 - 0s - loss: 0.0324 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 294/1000\n",
      "100/100 - 0s - loss: 0.0316 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2308 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 295/1000\n",
      "100/100 - 0s - loss: 0.0337 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2308 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 296/1000\n",
      "100/100 - 0s - loss: 0.0298 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2306 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 297/1000\n",
      "100/100 - 0s - loss: 0.0290 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 298/1000\n",
      "100/100 - 0s - loss: 0.0250 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2306 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 299/1000\n",
      "100/100 - 0s - loss: 0.0266 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 300/1000\n",
      "100/100 - 0s - loss: 0.0288 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2309 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 301/1000\n",
      "100/100 - 0s - loss: 0.0260 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2313 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "100/100 - 0s - loss: 0.0257 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2320 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 303/1000\n",
      "100/100 - 0s - loss: 0.0229 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2326 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 304/1000\n",
      "100/100 - 0s - loss: 0.0285 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2332 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 305/1000\n",
      "100/100 - 0s - loss: 0.0306 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2335 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 306/1000\n",
      "100/100 - 0s - loss: 0.0321 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2338 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 307/1000\n",
      "100/100 - 0s - loss: 0.0246 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2339 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 308/1000\n",
      "100/100 - 0s - loss: 0.0261 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2339 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 309/1000\n",
      "100/100 - 0s - loss: 0.0232 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2340 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 310/1000\n",
      "100/100 - 0s - loss: 0.0248 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2340 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 311/1000\n",
      "100/100 - 0s - loss: 0.0253 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2338 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 312/1000\n",
      "100/100 - 0s - loss: 0.0248 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2337 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 313/1000\n",
      "100/100 - 0s - loss: 0.0240 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2335 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 314/1000\n",
      "100/100 - 0s - loss: 0.0269 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2331 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 315/1000\n",
      "100/100 - 0s - loss: 0.0291 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2322 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 316/1000\n",
      "100/100 - 0s - loss: 0.0257 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2312 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 317/1000\n",
      "100/100 - 0s - loss: 0.0233 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2303 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 318/1000\n",
      "100/100 - 0s - loss: 0.0243 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2294 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 319/1000\n",
      "100/100 - 0s - loss: 0.0243 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2288 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 320/1000\n",
      "100/100 - 0s - loss: 0.0238 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2282 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 321/1000\n",
      "100/100 - 0s - loss: 0.0228 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2278 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 322/1000\n",
      "100/100 - 0s - loss: 0.0249 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2274 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 323/1000\n",
      "100/100 - 0s - loss: 0.0214 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2272 - val_acc: 0.9118 - val_f1_score: 0.9091 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 324/1000\n",
      "100/100 - 0s - loss: 0.0247 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2269 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 325/1000\n",
      "100/100 - 0s - loss: 0.0261 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2268 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 326/1000\n",
      "100/100 - 0s - loss: 0.0254 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2269 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 327/1000\n",
      "100/100 - 0s - loss: 0.0236 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2271 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 328/1000\n",
      "100/100 - 0s - loss: 0.0257 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2271 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 329/1000\n",
      "100/100 - 0s - loss: 0.0239 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2271 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 330/1000\n",
      "100/100 - 0s - loss: 0.0229 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2272 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 331/1000\n",
      "100/100 - 0s - loss: 0.0247 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2272 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 332/1000\n",
      "100/100 - 0s - loss: 0.0237 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2271 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 333/1000\n",
      "100/100 - 0s - loss: 0.0225 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2269 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 334/1000\n",
      "100/100 - 0s - loss: 0.0265 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2267 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 335/1000\n",
      "100/100 - 0s - loss: 0.0236 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2265 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 336/1000\n",
      "100/100 - 0s - loss: 0.0226 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2265 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 337/1000\n",
      "100/100 - 0s - loss: 0.0223 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2267 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 338/1000\n",
      "100/100 - 0s - loss: 0.0200 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2269 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 339/1000\n",
      "100/100 - 0s - loss: 0.0243 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2272 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000\n",
      "100/100 - 0s - loss: 0.0245 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2275 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 341/1000\n",
      "100/100 - 0s - loss: 0.0188 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2279 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 342/1000\n",
      "100/100 - 0s - loss: 0.0238 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2282 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 343/1000\n",
      "100/100 - 0s - loss: 0.0218 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2283 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 344/1000\n",
      "100/100 - 0s - loss: 0.0212 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2283 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 345/1000\n",
      "100/100 - 0s - loss: 0.0211 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2287 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 346/1000\n",
      "100/100 - 0s - loss: 0.0219 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2291 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 347/1000\n",
      "100/100 - 0s - loss: 0.0227 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2293 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 348/1000\n",
      "100/100 - 0s - loss: 0.0213 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2294 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 349/1000\n",
      "100/100 - 0s - loss: 0.0209 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2296 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 350/1000\n",
      "100/100 - 0s - loss: 0.0219 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2296 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 351/1000\n",
      "100/100 - 0s - loss: 0.0209 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2298 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 352/1000\n",
      "100/100 - 0s - loss: 0.0190 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2299 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 353/1000\n",
      "100/100 - 0s - loss: 0.0176 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2298 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 354/1000\n",
      "100/100 - 0s - loss: 0.0176 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2296 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 355/1000\n",
      "100/100 - 0s - loss: 0.0157 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2293 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 356/1000\n",
      "100/100 - 0s - loss: 0.0207 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2291 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 357/1000\n",
      "100/100 - 0s - loss: 0.0218 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2285 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 358/1000\n",
      "100/100 - 0s - loss: 0.0166 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2279 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 359/1000\n",
      "100/100 - 0s - loss: 0.0198 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2273 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 360/1000\n",
      "100/100 - 0s - loss: 0.0189 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2266 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 361/1000\n",
      "100/100 - 0s - loss: 0.0190 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2260 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 362/1000\n",
      "100/100 - 0s - loss: 0.0170 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2254 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 363/1000\n",
      "100/100 - 0s - loss: 0.0187 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2247 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 364/1000\n",
      "100/100 - 0s - loss: 0.0174 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2241 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 365/1000\n",
      "100/100 - 0s - loss: 0.0177 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2237 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 366/1000\n",
      "100/100 - 0s - loss: 0.0174 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2234 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 367/1000\n",
      "100/100 - 0s - loss: 0.0184 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2233 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 368/1000\n",
      "100/100 - 0s - loss: 0.0209 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2234 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 369/1000\n",
      "100/100 - 0s - loss: 0.0199 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2238 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 370/1000\n",
      "100/100 - 0s - loss: 0.0196 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2245 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 371/1000\n",
      "100/100 - 0s - loss: 0.0156 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2252 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 372/1000\n",
      "100/100 - 0s - loss: 0.0170 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2261 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 373/1000\n",
      "100/100 - 0s - loss: 0.0165 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2269 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 374/1000\n",
      "100/100 - 0s - loss: 0.0154 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2279 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 375/1000\n",
      "100/100 - 0s - loss: 0.0161 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2287 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 376/1000\n",
      "100/100 - 0s - loss: 0.0169 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2296 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 377/1000\n",
      "100/100 - 0s - loss: 0.0152 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2304 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "100/100 - 0s - loss: 0.0171 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2311 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 379/1000\n",
      "100/100 - 0s - loss: 0.0188 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2315 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 380/1000\n",
      "100/100 - 0s - loss: 0.0183 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2316 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 381/1000\n",
      "100/100 - 0s - loss: 0.0150 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2315 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 382/1000\n",
      "100/100 - 0s - loss: 0.0153 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2312 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 383/1000\n",
      "100/100 - 0s - loss: 0.0161 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2311 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 384/1000\n",
      "100/100 - 0s - loss: 0.0166 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2310 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 385/1000\n",
      "100/100 - 0s - loss: 0.0160 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2309 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 386/1000\n",
      "100/100 - 0s - loss: 0.0194 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2309 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 387/1000\n",
      "100/100 - 0s - loss: 0.0175 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2307 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 388/1000\n",
      "100/100 - 0s - loss: 0.0164 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2305 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 389/1000\n",
      "100/100 - 0s - loss: 0.0181 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2301 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 390/1000\n",
      "100/100 - 0s - loss: 0.0154 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2298 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 391/1000\n",
      "100/100 - 0s - loss: 0.0164 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2295 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 392/1000\n",
      "100/100 - 0s - loss: 0.0182 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2291 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 393/1000\n",
      "100/100 - 0s - loss: 0.0140 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2290 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 394/1000\n",
      "100/100 - 0s - loss: 0.0168 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2289 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 395/1000\n",
      "100/100 - 0s - loss: 0.0169 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2289 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 396/1000\n",
      "100/100 - 0s - loss: 0.0151 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2290 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 397/1000\n",
      "100/100 - 0s - loss: 0.0144 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2293 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 398/1000\n",
      "100/100 - 0s - loss: 0.0158 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2294 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 399/1000\n",
      "100/100 - 0s - loss: 0.0155 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2300 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 400/1000\n",
      "100/100 - 0s - loss: 0.0146 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2303 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 401/1000\n",
      "100/100 - 0s - loss: 0.0122 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2306 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 402/1000\n",
      "100/100 - 0s - loss: 0.0135 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2310 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 403/1000\n",
      "100/100 - 0s - loss: 0.0143 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2313 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 404/1000\n",
      "100/100 - 0s - loss: 0.0144 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2310 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 405/1000\n",
      "100/100 - 0s - loss: 0.0122 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2306 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 406/1000\n",
      "100/100 - 0s - loss: 0.0150 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2300 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 407/1000\n",
      "100/100 - 0s - loss: 0.0128 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2291 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 408/1000\n",
      "100/100 - 0s - loss: 0.0151 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2279 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 409/1000\n",
      "100/100 - 0s - loss: 0.0154 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2270 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 410/1000\n",
      "100/100 - 0s - loss: 0.0136 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2261 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 411/1000\n",
      "100/100 - 0s - loss: 0.0139 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2251 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 412/1000\n",
      "100/100 - 0s - loss: 0.0158 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2241 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 413/1000\n",
      "100/100 - 0s - loss: 0.0141 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2232 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 414/1000\n",
      "100/100 - 0s - loss: 0.0149 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2227 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 415/1000\n",
      "100/100 - 0s - loss: 0.0121 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2222 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/1000\n",
      "100/100 - 0s - loss: 0.0143 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2219 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 417/1000\n",
      "100/100 - 0s - loss: 0.0132 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2220 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 418/1000\n",
      "100/100 - 0s - loss: 0.0183 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2216 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 419/1000\n",
      "100/100 - 0s - loss: 0.0134 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2211 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 420/1000\n",
      "100/100 - 0s - loss: 0.0178 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2206 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 421/1000\n",
      "100/100 - 0s - loss: 0.0131 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2202 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 422/1000\n",
      "100/100 - 0s - loss: 0.0149 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2198 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 423/1000\n",
      "100/100 - 0s - loss: 0.0124 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2194 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 424/1000\n",
      "100/100 - 0s - loss: 0.0118 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2191 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 425/1000\n",
      "100/100 - 0s - loss: 0.0128 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2190 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 426/1000\n",
      "100/100 - 0s - loss: 0.0094 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2189 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 427/1000\n",
      "100/100 - 0s - loss: 0.0149 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2189 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 428/1000\n",
      "100/100 - 0s - loss: 0.0149 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2187 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 429/1000\n",
      "100/100 - 0s - loss: 0.0107 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2187 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 430/1000\n",
      "100/100 - 0s - loss: 0.0121 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2188 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 431/1000\n",
      "100/100 - 0s - loss: 0.0121 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2192 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 432/1000\n",
      "100/100 - 0s - loss: 0.0139 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2194 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 433/1000\n",
      "100/100 - 0s - loss: 0.0108 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2195 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 434/1000\n",
      "100/100 - 0s - loss: 0.0122 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2198 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 435/1000\n",
      "100/100 - 0s - loss: 0.0139 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2201 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 436/1000\n",
      "100/100 - 0s - loss: 0.0147 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2206 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 437/1000\n",
      "100/100 - 0s - loss: 0.0114 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2211 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 438/1000\n",
      "100/100 - 0s - loss: 0.0109 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2217 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 439/1000\n",
      "100/100 - 0s - loss: 0.0148 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2222 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 440/1000\n",
      "100/100 - 0s - loss: 0.0148 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2226 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 441/1000\n",
      "100/100 - 0s - loss: 0.0123 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2229 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 442/1000\n",
      "100/100 - 0s - loss: 0.0099 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2233 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 443/1000\n",
      "100/100 - 0s - loss: 0.0113 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2237 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 444/1000\n",
      "100/100 - 0s - loss: 0.0112 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2239 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 445/1000\n",
      "100/100 - 0s - loss: 0.0129 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2240 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 446/1000\n",
      "100/100 - 0s - loss: 0.0118 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2242 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 447/1000\n",
      "100/100 - 0s - loss: 0.0152 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2246 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 448/1000\n",
      "100/100 - 0s - loss: 0.0129 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2249 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 449/1000\n",
      "100/100 - 0s - loss: 0.0119 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2253 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 450/1000\n",
      "100/100 - 0s - loss: 0.0117 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2255 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 451/1000\n",
      "100/100 - 0s - loss: 0.0117 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2255 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 452/1000\n",
      "100/100 - 0s - loss: 0.0121 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2255 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 453/1000\n",
      "100/100 - 0s - loss: 0.0124 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2255 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "100/100 - 0s - loss: 0.0101 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2254 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 455/1000\n",
      "100/100 - 0s - loss: 0.0118 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2253 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 456/1000\n",
      "100/100 - 0s - loss: 0.0123 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2252 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 457/1000\n",
      "100/100 - 0s - loss: 0.0118 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2251 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 458/1000\n",
      "100/100 - 0s - loss: 0.0108 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2251 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 459/1000\n",
      "100/100 - 0s - loss: 0.0102 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2251 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 460/1000\n",
      "100/100 - 0s - loss: 0.0129 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2249 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 461/1000\n",
      "100/100 - 0s - loss: 0.0127 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2247 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 462/1000\n",
      "100/100 - 0s - loss: 0.0124 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2248 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 463/1000\n",
      "100/100 - 0s - loss: 0.0139 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2246 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 464/1000\n",
      "100/100 - 0s - loss: 0.0140 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2238 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 465/1000\n",
      "100/100 - 0s - loss: 0.0110 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2232 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 466/1000\n",
      "100/100 - 0s - loss: 0.0085 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2227 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 467/1000\n",
      "100/100 - 0s - loss: 0.0101 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2224 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 468/1000\n",
      "100/100 - 0s - loss: 0.0107 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2224 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 469/1000\n",
      "100/100 - 0s - loss: 0.0087 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2225 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 470/1000\n",
      "100/100 - 0s - loss: 0.0100 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2226 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 471/1000\n",
      "100/100 - 0s - loss: 0.0127 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2224 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 472/1000\n",
      "100/100 - 0s - loss: 0.0119 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2221 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 473/1000\n",
      "100/100 - 0s - loss: 0.0107 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2217 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 474/1000\n",
      "100/100 - 0s - loss: 0.0104 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2213 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 475/1000\n",
      "100/100 - 0s - loss: 0.0095 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2209 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 476/1000\n",
      "100/100 - 0s - loss: 0.0107 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2205 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 477/1000\n",
      "100/100 - 0s - loss: 0.0106 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2200 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 478/1000\n",
      "100/100 - 0s - loss: 0.0082 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2198 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Epoch 479/1000\n",
      "100/100 - 0s - loss: 0.0142 - acc: 1.0000 - f1_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2198 - val_acc: 0.9412 - val_f1_score: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000\n",
      "Validation accuracy: 0.9411764740943909, loss: 0.21977776288986206\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9411765, 0.21977776288986206)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model, will plot an accuracy char at the end\n",
    "train_ngram_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding new travelogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code blocks below are used to identify new travelogues within the unclassified part of the corpus.\n",
    "# Currently, those books are not included in our corpus repository, so this is disabled for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an already created model\n",
    "\n",
    "# dependencies = {\n",
    "#     'f1_score': f1_score,\n",
    "#     'precision': precision,\n",
    "#     'recall': recall\n",
    "# }\n",
    "\n",
    "# mlp_model = tf.keras.models.load_model(mlp_model_name, custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# travel_gt_path = books\n",
    "\n",
    "# with open(result_output, 'a') as out_file:\n",
    "#     out_file.write('Identifier,URL,Score\\n')\n",
    "    \n",
    "#     candidate_path = os.path.join(travel_gt_path, 'candidates')\n",
    "#     for fname in tqdm(os.listdir(candidate_path)):\n",
    "#         text = []\n",
    "#         if fname.endswith('.txt'):\n",
    "#              with open(os.path.join(candidate_path, fname)) as f:\n",
    "#                 text.append(f.read())\n",
    "#                 vectorized_text = vectorizer.transform(text)\n",
    "#                 vectorized_text = selector.transform(vectorized_text).astype('float32')\n",
    "#                 score = model_17.predict(vectorized_text)[0][0]\n",
    "#                 link = 'http://data.onb.ac.at/ABO/+%s' % fname[:-4]  # this links to the document in ABO\n",
    "#                 out_file.write(fname[:-4] + ',' + link + ',' + str(format(score, '.5f')) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
